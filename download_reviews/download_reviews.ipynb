{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on https://github.com/zhenzuo2/IS_590_Final/tree/master/Gather_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_folder_directory = '../../review_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Game Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs for Dota 2, PUBG, CS:GO, Warframe, Rainbow Six: Siege\n",
    "app_id_list = [570, 578080, 730, 230410, 359550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download game details based on app id\n",
    "def get_details(app_id: int, max_attempts: int = 10) -> dict:\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        response = requests.get(\"http://store.steampowered.com/api/appdetails?appids=\" + str(app_id))\n",
    "        if response.status_code != 429:\n",
    "            return response.json()\n",
    "        # If rate limited, wait and try again\n",
    "        time.sleep((2 ** attempts) + random.random())\n",
    "        attempts = attempts + 1\n",
    "    print(f\"Unable to retrieve product details for app_id = {app_id}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download details for all games in the list\n",
    "details = {}\n",
    "for app_id in tqdm(app_id_list):\n",
    "    d = get_details(app_id)\n",
    "    if d is not None:\n",
    "        details.update(d)\n",
    "        \n",
    "# Delete the \"success\" field, and create a dictionary of game data.\n",
    "for key in details.keys():\n",
    "    if details[key]['success'] :\n",
    "        details[key] = details[key]['data']\n",
    "    else:\n",
    "        details[key] = None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe and write to disk.\n",
    "game_details = pd.DataFrame.from_dict(details, orient='index')\n",
    "game_details.to_csv(f'{reviews_folder_directory}/game_details.csv', sep = '|', escapechar = '@', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Game Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(app_id: int, page: int, max_attempts: int = 10) -> dict:\n",
    "    \"\"\"Get a page of reviews for a given game.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    app_id : int\n",
    "        app_id to get reviews of\n",
    "    page : int\n",
    "        page number to get reviews of. Page 0 is reviews 0 - 99, page 1 is reviews 100-199, etc.\n",
    "    max_attempts: int, optional\n",
    "        maximum number of retries if steam rejects the API call. \n",
    "        Total time to timeout = max_attempts * (max_attempts-1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list(dict())\n",
    "        list of reviews, each review being a dictionary\n",
    "        \n",
    "    Documentation: https://partner.steamgames.com/doc/store/getreviews\n",
    "    \"\"\"\n",
    "    attempts = 0\n",
    "    # Each page is 100 reviews, so we offset by 100 each time\n",
    "    offset = page * 100\n",
    "    while attempts < max_attempts:\n",
    "        # Get recent reviews, in english, with 100 per page.\n",
    "        response = requests.get(\"http://store.steampowered.com/appreviews/\"+str(app_id)+ \n",
    "                                \"?json=1&filter=recent&language=english&num_per_page=100&start_offset=\" + str(offset))\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"reviews\"]\n",
    "        # If rate limited, wait and try again\n",
    "        time.sleep((2 * attempts))\n",
    "        attempts = attempts + 1\n",
    "    print(f\"Unable to retrieve reviews for app_id = {app_id}\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_author(review_json: dict) -> dict:\n",
    "    \"\"\"Flatten author data into the main attributes by side effect.\"\"\"\n",
    "    author_data = review_json.pop('author')\n",
    "    author_data = {'author__' + key : value for key, value in author_data.items()}\n",
    "    review_json.update(author_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed pages: {570: 64, 578080: 1250, 730: 1001, 230410: 13, 359550: 886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading reviews for 570 : 1it [00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate elements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading reviews for 578080 : 500it [12:02,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate elements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading reviews for 730 : 500it [16:38,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate elements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading reviews for 230410 : 1it [00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate elements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading reviews for 359550 : 2it [00:01,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate elements.\n",
      "{570: 64, 578080: 1749, 730: 1500, 230410: 13, 359550: 887}\n"
     ]
    }
   ],
   "source": [
    "# Download reviews for every game in list and add to a pandas df\n",
    "\n",
    "# Try and resume from the last page downloaded - otherwise, start from 0.\n",
    "try:\n",
    "    with open(f\"{reviews_folder_directory}/completed_pages.pkl\",\"rb\") as rf:\n",
    "        completed_pages = pickle.load(rf)\n",
    "    print(f'Completed pages: {completed_pages}')\n",
    "except:\n",
    "    print(\"No completed pages found, starting from zero.\")\n",
    "    completed_pages = {k : 0 for k in app_id_list}\n",
    "\n",
    "# For each game, download reviews\n",
    "for app_id in app_id_list:\n",
    "    # Remove one to check the page that failed previously\n",
    "    completed_pages[app_id] = max(0, completed_pages[app_id] - 1)\n",
    "    \n",
    "    # Try to add to the existing review dataframe, otherwise create a new one.\n",
    "    try:\n",
    "        game_reviews = pd.read_csv(f'{reviews_folder_directory}/{app_id}.csv', sep = '|', )\n",
    "    except:\n",
    "        game_reviews = pd.DataFrame(columns=['recommendationid', 'author__steamid', 'author__num_games_owned',\n",
    "                                             'author__num_reviews', 'author__playtime_forever', \n",
    "                                             'author__playtime_last_two_weeks', 'author__last_played',\n",
    "                                             'language', 'review', 'timestamp_created', 'timestamp_updated', \n",
    "                                             'voted_up', # If the review was voted positive\n",
    "                                             'votes_up', 'votes_funny', 'comment_count',\n",
    "                                             'steam_purchase', 'received_for_free', \n",
    "                                             'written_during_early_access'])\n",
    "\n",
    "    # Loop until we no longer get a result\n",
    "    with tqdm(desc=f\"Downloading reviews for {app_id} \") as bar:\n",
    "        try:\n",
    "            # Get 500 reviews\n",
    "            for i in range(500):\n",
    "                current_reviews = get_reviews(app_id, completed_pages[app_id])\n",
    "                if current_reviews == []:\n",
    "                    break\n",
    "                for review in current_reviews:\n",
    "                    flatten_author(review)\n",
    "                # Only keep the review information we save as columns\n",
    "                current_reviews = [{k : review[k] for k in game_reviews.columns} for review in current_reviews]\n",
    "                game_reviews = game_reviews.append(current_reviews)\n",
    "                # Incremenet offset\n",
    "                completed_pages[app_id] += 1\n",
    "                bar.update(1)\n",
    "                \n",
    "        # If we keyboard interupt, stop getting the current review and instead save our data.\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "    \n",
    "    # Set reccommendationid to neumeric (for dropping duplicates)\n",
    "    length_with_dupes = game_reviews.shape[0]\n",
    "    game_reviews['recommendationid'] = game_reviews['recommendationid'].apply(pd.to_numeric)\n",
    "    #game_reviews.drop_duplicates('recommendationid', keep = 'last', inplace=True)\n",
    "    \n",
    "    print(f\"Removed {length_with_dupes - game_reviews.shape[0]} duplicate elements.\")\n",
    "    \n",
    "    \n",
    "    # Save results \n",
    "    game_reviews.to_csv(f'{reviews_folder_directory}/{app_id}.csv', sep = '|', escapechar = '@', index = False)\n",
    "        \n",
    "print(completed_pages)\n",
    "with open(f\"{reviews_folder_directory}/completed_pages.pkl\",\"wb\") as wf:\n",
    "    pickle.dump(completed_pages, wf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
